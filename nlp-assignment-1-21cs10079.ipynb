{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import nltk   \n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\n\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import SVC\n\nimport seaborn as sns\nimport nltk\nfrom nltk.corpus import treebank\nfrom collections import defaultdict, Counter","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **TASK 1 : POS Tagging on treebank corpus**","metadata":{}},{"cell_type":"markdown","source":"**Step 1: Load and preprocess the treebank corpus**","metadata":{}},{"cell_type":"code","source":"nltk.download('treebank')\n\n\ntagged_sentences = treebank.tagged_sents()\ntrain_data = []\nfor sentence in tagged_sentences:\n    train_data.extend(sentence)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tags = [tag for _, tag in train_data]\nwords = [word for word, _ in train_data]\n\ntag_counts = Counter(tags)\nword_counts = Counter(words)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_tags = list(set(tags))\nprint(len(unique_tags), unique_tags, sep='\\n\\n', end='\\n\\n')\n\nunique_words = list(set(words))\nprint(len(unique_words), unique_words[:50], sep='\\n\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" **Step 2: Calculate Transition and Emission Probabilities**","metadata":{}},{"cell_type":"code","source":"# P(tag_2|tag_1) aka Transition Probability\ndef transition_probability(tag_2, tag_1):\n    count_tag_1 = 0\n    count_tag_2_given_tag1 = 0\n    tag_bigram_counts = defaultdict(int)\n\n    for index in range(len(tags) - 1):\n        if tags[index] == tag_1:\n            count_tag_1 += 1\n            if tags[index + 1] == tag_2:\n                count_tag_2_given_tag1 += 1\n    \n    total_tags = len(set(tags))  \n    # Add-one Laplace smoothing\n    probability = (count_tag_2_given_tag1 + 1) / (count_tag_1 + total_tags)\n    return probability\n\n# P(word|tag) aka Emission Probability\n\ndef emission_probability(word, tag):\n    # Extract all words with the given tag\n    tag_list = [tagged_word for tagged_word in train_data if tagged_word[1] == tag]\n    \n    # Count the number of times the specific word appears with the tag\n    word_given_tag_list = [tagged_word for tagged_word in tag_list if tagged_word[0] == word]\n    \n    word_count = len(word_given_tag_list)\n    tag_count = len(tag_list)\n    \n    # Add-one Laplace smoothing\n    total_vocabulary = len(set([word_tag[0] for word_tag in train_data]))\n    probability = (word_count + 1) / (tag_count + total_vocabulary)\n    return  probability\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize an output\nprint(transition_probability('JJ', 'DT'))\n\n# Visualize an output\nprint(emission_probability('a', 'DT'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def viterbi_algorithm(sentence):\n    # Initialize matrices\n    num_tags = len(unique_tags)\n    num_words = len(sentence)\n    viterbi_matrix = np.zeros((num_tags, num_words))\n    backpointer_matrix = np.zeros((num_tags, num_words), dtype=int)\n\n    # Initialization step\n    for i, tag in enumerate(unique_tags):\n        emission_prob = emission_probability(sentence[0], tag)\n        viterbi_matrix[i, 0] = emission_prob\n        backpointer_matrix[i, 0] = 0  # No backpointer needed for the first word\n\n    # Recursion step\n    for t in range(1, num_words):\n        for i, tag in enumerate(unique_tags):\n            max_prob = 0\n            max_state = 0\n            for j, prev_tag in enumerate(unique_tags):\n                trans_prob = transition_probability(tag, prev_tag)\n                emiss_prob = emission_probability(sentence[t], tag)\n                prob = viterbi_matrix[j, t-1] * trans_prob * emiss_prob\n                if prob > max_prob:\n                    max_prob = prob\n                    max_state = j\n            viterbi_matrix[i, t] = max_prob\n            backpointer_matrix[i, t] = max_state\n\n    # Termination step\n    best_path_prob = np.max(viterbi_matrix[:, num_words-1])\n    best_last_tag = np.argmax(viterbi_matrix[:, num_words-1])\n\n    # Backtracking to find the best path\n    best_path = [best_last_tag]\n    for t in range(num_words-1, 0, -1):\n        best_path.insert(0, backpointer_matrix[best_path[0], t])\n\n    # Convert tag indices to tag names\n    best_tag_sequence = [unique_tags[i] for i in best_path]\n\n    return best_tag_sequence, best_path_prob\n\n# # Test the Viterbi Algorithm\n# test_sentence = ['The', 'dog', 'barked']\n# predicted_tags, probability = viterbi_algorithm(test_sentence)\n\n# print(f\"Test Sentence: {test_sentence}\")\n# print(f\"Predicted Tags: {predicted_tags}\")\n# print(f\"Probability of the Best Path: {probability:.4f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **TASK 2 : Vanilla Emotion Recognizer**","metadata":{}},{"cell_type":"markdown","source":"**Step 1 :  Load and preprocess the corpus**","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\ndataset = load_dataset(\"dair-ai/emotion\",\"split\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = dataset[\"train\"]\nvalidation_data = dataset[\"validation\"]\ntest_data = dataset[\"test\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to preprocess data and extract texts and labels\ndef preprocess_data(data):\n    texts = [item[\"text\"] for item in data]\n    labels = [item[\"label\"] for item in data]  # Assuming 'label' is the key for emotions\n    return texts, labels\n\n# Preprocess the datasets\ntrain_texts, train_labels = preprocess_data(train_data)\nvalidation_texts, validation_labels = preprocess_data(validation_data)\ntest_texts, test_labels = preprocess_data(test_data)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Step 2 : Sentence embeddings**","metadata":{}},{"cell_type":"code","source":"vectorizer = TfidfVectorizer(max_features=5000)\ntrain_embeddings = vectorizer.fit_transform(train_texts)\nvalidation_embeddings = vectorizer.transform(validation_texts)\ntest_embeddings = vectorizer.transform(test_texts)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Step 3.1 : Naive Bayes for emotion recognition**","metadata":{}},{"cell_type":"code","source":"# Train Naive Bayes Classifier\nnb_classifier = MultinomialNB()\nnb_classifier.fit(train_embeddings, train_labels)\nvalidation_preds = nb_classifier.predict(validation_embeddings)\ntest_preds = nb_classifier.predict(test_embeddings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate Naive Bayes Classifier\nprint(\"Validation Accuracy (Naive Bayes):\", accuracy_score(validation_labels, validation_preds))\nprint(\"Validation Classification Report (Naive Bayes):\\n\", classification_report(validation_labels, validation_preds, zero_division=1))\nprint(\"Test Accuracy (Naive Bayes):\", accuracy_score(test_labels, test_preds))\nprint(\"Test Classification Report (Naive Bayes):\\n\", classification_report(test_labels, test_preds, zero_division=1))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix for Naive Bayes\ncm = confusion_matrix(test_labels, test_preds, labels=nb_classifier.classes_)\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=nb_classifier.classes_, yticklabels=nb_classifier.classes_)\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Step 3.2 : SVM for emotion recognition**","metadata":{}},{"cell_type":"code","source":"# Train SVM Classifier with class weights\nsvm_classifier = SVC(kernel='linear', class_weight='balanced')\nsvm_classifier.fit(train_embeddings, train_labels)\nvalidation_preds_svm = svm_classifier.predict(validation_embeddings)\ntest_preds_svm = svm_classifier.predict(test_embeddings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate SVM Classifier with class weights\n\nprint(\"Validation Accuracy (SVM):\", accuracy_score(validation_labels, validation_preds_svm))\nprint(\"Validation Classification Report (SVM):\\n\", classification_report(validation_labels, validation_preds_svm, zero_division=1))\nprint(\"Test Accuracy (SVM):\", accuracy_score(test_labels, test_preds_svm))\nprint(\"Test Classification Report (SVM):\\n\", classification_report(test_labels, test_preds_svm, zero_division=1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate the confusion matrix\ncm_svm = confusion_matrix(test_labels, test_preds_svm, labels=svm_classifier.classes_)\n\n# Visualize the confusion matrix using a heatmap\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm_svm, annot=True, fmt='d', cmap='Blues', xticklabels=svm_classifier.classes_, yticklabels=svm_classifier.classes_)\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.title('Confusion Matrix for SVM Classifier')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Task 3 : Improved Emotion Recognizer**","metadata":{}},{"cell_type":"code","source":"from sklearn.pipeline import FeatureUnion\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.metrics import classification_report\nfrom nltk.tokenize import word_tokenize\n\n# Custom transformer to extract POS tags and represent as features\nclass POSTaggerTransformer(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        pos_features = []\n        for sentence in X:\n            tokens = word_tokenize(sentence)\n            pos_tags, _ = viterbi_algorithm(tokens)\n            pos_features.append(' '.join(pos_tags))\n        return pos_features\n\n# Combine TF-IDF embeddings with POS tag features\nclass CombinedFeatures(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        self.tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n        self.pos_tagger = POSTaggerTransformer()\n\n    def fit(self, X, y=None):\n        pos_tagged_data = self.pos_tagger.transform(X)\n        self.tfidf_vectorizer.fit(X + pos_tagged_data)\n        return self\n\n    def transform(self, X, y=None):\n        tfidf_features = self.tfidf_vectorizer.transform(X).toarray()\n        pos_tagged_data = self.pos_tagger.transform(X)\n        pos_tfidf_features = self.tfidf_vectorizer.transform(pos_tagged_data).toarray()\n        combined_features = np.hstack((tfidf_features, pos_tfidf_features))\n        return combined_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Load the Twitter messages dataset\ndataset = load_dataset(\"dair-ai/emotion\",\"split\")\n\n# Extract text and labels\nX_train, y_train = dataset['train']['text'], dataset['train']['label']\nX_val, y_val = dataset['validation']['text'], dataset['validation']['label']\nX_test, y_test = dataset['test']['text'], dataset['test']['label']\n\n# Example usage\ncombined_features_extractor = CombinedFeatures()\nX_train_combined = combined_features_extractor.fit_transform(X_train)\nX_val_combined = combined_features_extractor.transform(X_val)\nX_test_combined = combined_features_extractor.transform(X_test)\n\n# Train Naive Bayes Classifier\nnb_classifier = MultinomialNB()\nnb_classifier.fit(X_train_combined, y_train)\nnb_val_preds = nb_classifier.predict(X_val_combined)\nnb_test_preds = nb_classifier.predict(X_test_combined)\n\nprint(\"Naive Bayes Validation Accuracy:\", accuracy_score(y_val, nb_val_preds))\nprint(\"Naive Bayes Validation Classification Report:\\n\", classification_report(y_val, nb_val_preds, zero_division=1))\nprint(\"Naive Bayes Test Accuracy:\", accuracy_score(y_test, nb_test_preds))\nprint(\"Naive Bayes Test Classification Report:\\n\", classification_report(y_test, nb_test_preds, zero_division=1))\n\n# Train SVM Classifier with class weights\nsvm_classifier = SVC(kernel='linear', class_weight='balanced')\nsvm_classifier.fit(X_train_combined, y_train)\nsvm_val_preds = svm_classifier.predict(X_val_combined)\nsvm_test_preds = svm_classifier.predict(X_test_combined)\n\nprint(\"SVM Validation Accuracy:\", accuracy_score(y_val, svm_val_preds))\nprint(\"SVM Validation Classification Report:\\n\", classification_report(y_val, svm_val_preds, zero_division=1))\nprint(\"SVM Test Accuracy:\", accuracy_score(y_test, svm_test_preds))\nprint(\"SVM Test Classification Report:\\n\", classification_report(y_test, svm_test_preds, zero_division=1))\n\n# Generate confusion matrix for SVM\ncm_svm = confusion_matrix(y_test, svm_test_preds, labels=svm_classifier.classes_)\n\n# Visualize the confusion matrix using a heatmap\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm_svm, annot=True, fmt='d', cmap='Blues', xticklabels=svm_classifier.classes_, yticklabels=svm_classifier.classes_)\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.title('Confusion Matrix for SVM Classifier')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}